{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49ccc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aab33817",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = 'audio'\n",
    "SPEC_DIR = 'spec_images'\n",
    "META_PATH = 'metadata.csv'\n",
    "\n",
    "WINDOW_SIZE = 3.0  # seconds\n",
    "HOP_SIZE = 1.5     # seconds\n",
    "SR = 22050         # sampling rate\n",
    "IMG_SIZE = 128     # spectrogram image size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4759a189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1843/1843 [03:56<00:00,  7.80it/s]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(SPEC_DIR, exist_ok=True)\n",
    "meta_df = pd.read_csv(META_PATH)  # columns: filename,label\n",
    "\n",
    "label_map = {label: idx for idx, label in enumerate(meta_df['diagnosis'].unique())}\n",
    "label_df = meta_df.set_index('id')['diagnosis'].to_dict()\n",
    "\n",
    "def save_spec_patch(y, sr, out_path):\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024, hop_length=512, n_mels=128)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    S_img = Image.fromarray(S_dB).resize((IMG_SIZE, IMG_SIZE))\n",
    "    S_img = S_img.convert('L')  # grayscale\n",
    "    S_img.save(out_path)\n",
    "\n",
    "for fname in tqdm(os.listdir(AUDIO_DIR)):\n",
    "    if not fname.endswith('.wav'): continue\n",
    "    file_id = os.path.splitext(fname)[0]\n",
    "    y, _ = librosa.load(os.path.join(AUDIO_DIR, fname), sr=SR)\n",
    "    duration = librosa.get_duration(y=y, sr=SR)\n",
    "    \n",
    "    win_len = int(WINDOW_SIZE * SR)\n",
    "    hop_len = int(HOP_SIZE * SR)\n",
    "    output_dir = os.path.join(SPEC_DIR, file_id)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for i, start in enumerate(np.arange(0, duration - WINDOW_SIZE, HOP_SIZE)):\n",
    "        s = int(start * SR)\n",
    "        y_win = y[s : s + win_len]\n",
    "        out_path = os.path.join(output_dir, f\"{file_id}_{i}.png\")\n",
    "        save_spec_patch(y_win, SR, out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10c52fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecPatchDataset(Dataset):\n",
    "    def __init__(self, root_dir, label_dict, transform=None):\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        self.transform = transform or transforms.ToTensor()\n",
    "\n",
    "        for file_id in os.listdir(root_dir):\n",
    "            class_label = label_dict[file_id + \".wav\"]\n",
    "            label_idx = label_map[class_label]\n",
    "            file_folder = os.path.join(root_dir, file_id)\n",
    "            for img in os.listdir(file_folder):\n",
    "                self.samples.append(os.path.join(file_folder, img))\n",
    "                self.labels.append(label_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.samples[idx]).convert('L')\n",
    "        img = self.transform(img)\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ba598fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(64 * 13 * 13, 128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)  # ← flatten\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f15d7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnosis\n",
      "COPD              64\n",
      "Healthy           26\n",
      "URTI              14\n",
      "Bronchiectasis     7\n",
      "Bronchiolitis      6\n",
      "Pneumonia          6\n",
      "LRTI               2\n",
      "Asthma             1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(meta_df['diagnosis'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3900bede",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m         stratify_labels.append(\u001b[33m'\u001b[39m\u001b[33mUnknown\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# Handle missing cases\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Split with aligned labels\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m train_ids, val_ids = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstratify_labels\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Update label dictionaries\u001b[39;00m\n\u001b[32m     30\u001b[39m train_labels = {fname: meta_df.loc[meta_df[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m] == \u001b[38;5;28mint\u001b[39m(fname.split(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m]), \u001b[33m'\u001b[39m\u001b[33mdiagnosis\u001b[39m\u001b[33m'\u001b[39m].values[\u001b[32m0\u001b[39m]\n\u001b[32m     31\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m train_ids}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Minh_Workspace/.conda/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Minh_Workspace/.conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2872\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2868\u001b[39m         CVClass = ShuffleSplit\n\u001b[32m   2870\u001b[39m     cv = CVClass(test_size=n_test, train_size=n_train, random_state=random_state)\n\u001b[32m-> \u001b[39m\u001b[32m2872\u001b[39m     train, test = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2874\u001b[39m train, test = ensure_common_namespace_device(arrays[\u001b[32m0\u001b[39m], train, test)\n\u001b[32m   2876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   2877\u001b[39m     chain.from_iterable(\n\u001b[32m   2878\u001b[39m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[32m   2879\u001b[39m     )\n\u001b[32m   2880\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Minh_Workspace/.conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:1909\u001b[39m, in \u001b[36mBaseShuffleSplit.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m   1879\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[32m   1880\u001b[39m \n\u001b[32m   1881\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1906\u001b[39m \u001b[33;03mto an integer.\u001b[39;00m\n\u001b[32m   1907\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1908\u001b[39m X, y, groups = indexable(X, y, groups)\n\u001b[32m-> \u001b[39m\u001b[32m1909\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1910\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Minh_Workspace/.conda/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2318\u001b[39m, in \u001b[36mStratifiedShuffleSplit._iter_indices\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m   2316\u001b[39m class_counts = np.bincount(y_indices)\n\u001b[32m   2317\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.min(class_counts) < \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2318\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2319\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe least populated class in y has only 1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2320\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m member, which is too few. The minimum\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m number of groups for any class cannot\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m be less than 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2323\u001b[39m     )\n\u001b[32m   2325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train < n_classes:\n\u001b[32m   2326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m should be greater or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m % (n_train, n_classes)\n\u001b[32m   2329\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Get all WAV files\n",
    "file_ids = [f for f in os.listdir(AUDIO_DIR) if f.endswith('.wav')]\n",
    "\n",
    "# Extract patient IDs from filenames (first part before '_')\n",
    "patient_ids = [f.split('_')[0] for f in file_ids]\n",
    "\n",
    "# Map each file to its patient's diagnosis\n",
    "stratify_labels = []\n",
    "for pid in patient_ids:\n",
    "    try:\n",
    "        diagnosis = meta_df.loc[meta_df['id'] == int(pid), 'diagnosis'].values[0]\n",
    "        stratify_labels.append(diagnosis)\n",
    "    except:\n",
    "        print(f\"Warning: No diagnosis found for patient {pid}\")\n",
    "        stratify_labels.append('Unknown')  # Handle missing cases\n",
    "\n",
    "# Split with aligned labels\n",
    "train_ids, val_ids = train_test_split(\n",
    "    file_ids,\n",
    "    test_size=0.2, \n",
    "    stratify=stratify_labels\n",
    ")\n",
    "\n",
    "# Update label dictionaries\n",
    "train_labels = {fname: meta_df.loc[meta_df['id'] == int(fname.split('_')[0]), 'diagnosis'].values[0]\n",
    "                for fname in train_ids}\n",
    "val_labels = {fname: meta_df.loc[meta_df['id'] == int(fname.split('_')[0]), 'diagnosis'].values[0]\n",
    "              for fname in val_ids}\n",
    "\n",
    "# Create datasets\n",
    "train_ds = SpecPatchDataset(SPEC_DIR, train_labels, transform)\n",
    "val_ds = SpecPatchDataset(SPEC_DIR, val_labels, transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(num_classes=len(label_map)).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1, 16):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccac1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        preds = model(imgs).argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Validation Accuracy: {correct / total:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
